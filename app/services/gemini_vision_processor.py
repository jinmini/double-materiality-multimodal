"""
Gemini Vision API ê¸°ë°˜ ë¬¸ì„œ ì²˜ë¦¬ ì„œë¹„ìŠ¤
"""

import logging
import time
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional

from app.infrastructure.clients.pdf_converter import PDFConverter
from app.infrastructure.clients.gemini_client import GeminiClient
from app.dependencies.clients import get_cost_manager_client

logger = logging.getLogger(__name__)

class GeminiVisionDocumentProcessor:
    """Gemini Vision API ê¸°ë°˜ ë¬¸ì„œ ì²˜ë¦¬ê¸°"""
    
    def __init__(self, gemini_client: GeminiClient, pdf_converter: PDFConverter = None):
        """
        Args:
            gemini_client: Gemini API í´ë¼ì´ì–¸íŠ¸
            pdf_converter: PDF ë³€í™˜ê¸° (ê¸°ë³¸ê°’: 200 DPI)
        """
        self.gemini_client = gemini_client
        self.pdf_converter = pdf_converter or PDFConverter(dpi=200)
        self.cost_manager = get_cost_manager_client()
        
        # ì¤‘ëŒ€ì„± í‰ê°€ ê´€ë ¨ í‚¤ì›Œë“œ
        self.materiality_keywords = [
            "ì¤‘ëŒ€ì„±", "materiality", "ì¤‘ìš”ë„", "ì´í•´ê´€ê³„ì", "stakeholder",
            "ë§¤íŠ¸ë¦­ìŠ¤", "matrix", "ì´ìŠˆ", "issue", "ì˜í–¥ë„", "ê´€ì‹¬ë„"
        ]
    
    async def process_document(self, pdf_path: str) -> Dict[str, Any]:
        """
        PDF ë¬¸ì„œë¥¼ Gemini Vision APIë¡œ ë¶„ì„í•˜ì—¬ ì¤‘ëŒ€ì„± ì´ìŠˆ ì¶”ì¶œ
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            
        Returns:
            Dict: ì²˜ë¦¬ ê²°ê³¼
        """
        logger.info(f"ğŸ” Gemini Vision ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘: {pdf_path}")
        start_time = time.time()
        
        try:
            # 1. PDF ì •ë³´ ì¡°íšŒ
            pdf_info = self.pdf_converter.get_pdf_info(pdf_path)
            logger.info(f"ğŸ“„ PDF ì •ë³´: {pdf_info['total_pages']}í˜ì´ì§€, {pdf_info['file_size']/1024/1024:.1f}MB")
            
            # 2. PDF â†’ ì´ë¯¸ì§€ ë³€í™˜
            logger.info("ğŸ–¼ï¸ PDF â†’ ì´ë¯¸ì§€ ë³€í™˜ ì‹œì‘")
            page_images = self.pdf_converter.convert_pdf_to_images(pdf_path)
            
            # 3. ì¤‘ëŒ€ì„± í‰ê°€ ê´€ë ¨ í˜ì´ì§€ ì‹ë³„
            logger.info("ğŸ” ì¤‘ëŒ€ì„± í‰ê°€ í˜ì´ì§€ ì‹ë³„ ì¤‘")
            materiality_pages = await self._identify_materiality_pages(page_images)
            
            if not materiality_pages:
                logger.warning("âš ï¸ ì¤‘ëŒ€ì„± í‰ê°€ ê´€ë ¨ í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                # ëª¨ë“  í˜ì´ì§€ì—ì„œ ë¶„ì„ ì‹œë„
                materiality_pages = page_images[:5]  # ì²˜ìŒ 5í˜ì´ì§€ë§Œ
            
            # 4. ì¤‘ëŒ€ì„± ì´ìŠˆ ì¶”ì¶œ
            logger.info(f"ğŸ¯ {len(materiality_pages)}ê°œ í˜ì´ì§€ì—ì„œ ì¤‘ëŒ€ì„± ì´ìŠˆ ì¶”ì¶œ")
            materiality_issues = await self._extract_materiality_issues(materiality_pages)
            
            # 5. ESG ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
            esg_categorized = self._categorize_esg_issues(materiality_issues)
            
            # 6. ê²°ê³¼ êµ¬ì„±
            processing_time = time.time() - start_time
            
            result = {
                "file_info": {
                    "filename": Path(pdf_path).name,
                    "file_id": Path(pdf_path).stem,
                    "processed_at": datetime.now().isoformat(),
                    "processing_time": f"{processing_time:.2f}ì´ˆ"
                },
                "document_analysis": {
                    "total_pages": pdf_info["total_pages"],
                    "analyzed_pages": len(materiality_pages),
                    "materiality_pages_found": len([p for p in page_images if self._contains_materiality_keywords(p)]),
                    "has_images": pdf_info["has_images"],
                    "has_text": pdf_info["has_text"]
                },
                "materiality_issues": materiality_issues,
                "esg_content_summary": {
                    category: len(issues) 
                    for category, issues in esg_categorized.items()
                },
                "esg_categorized": esg_categorized,
                "extraction_method": "gemini_vision",
                "extraction_confidence": "high"
            }
            
            logger.info(f"âœ… Gemini Vision ì²˜ë¦¬ ì™„ë£Œ: {len(materiality_issues)}ê°œ ì´ìŠˆ ì¶”ì¶œ ({processing_time:.2f}ì´ˆ)")
            return result
            
        except Exception as e:
            logger.error(f"âŒ Gemini Vision ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            raise Exception(f"ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    async def _identify_materiality_pages(self, page_images: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì¤‘ëŒ€ì„± í‰ê°€ ê´€ë ¨ í˜ì´ì§€ ì‹ë³„"""
        materiality_pages = []
        
        # ë¨¼ì € í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ í•„í„°ë§
        candidate_pages = [
            page for page in page_images 
            if self._contains_materiality_keywords(page)
        ]
        
        if not candidate_pages:
            # í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ Gemini Visionìœ¼ë¡œ ì‹ë³„
            logger.info("ğŸ” í‚¤ì›Œë“œ ê¸°ë°˜ í•„í„°ë§ ì‹¤íŒ¨, Gemini Visionìœ¼ë¡œ í˜ì´ì§€ ì‹ë³„")
            
            for page in page_images[:10]:  # ì²˜ìŒ 10í˜ì´ì§€ë§Œ í™•ì¸
                try:
                    is_materiality = await self._is_materiality_page(page)
                    if is_materiality:
                        materiality_pages.append(page)
                        logger.info(f"âœ… ì¤‘ëŒ€ì„± í‰ê°€ í˜ì´ì§€ ë°œê²¬: {page['page_number']}")
                except Exception as e:
                    logger.warning(f"âš ï¸ í˜ì´ì§€ {page['page_number']} ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
                    continue
        else:
            materiality_pages = candidate_pages
            logger.info(f"âœ… í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ {len(materiality_pages)}ê°œ ì¤‘ëŒ€ì„± í‰ê°€ í˜ì´ì§€ ë°œê²¬")
        
        return materiality_pages
    
    def _contains_materiality_keywords(self, page: Dict[str, Any]) -> bool:
        """í˜ì´ì§€ì— ì¤‘ëŒ€ì„± í‰ê°€ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (ì„ì‹œ êµ¬í˜„)"""
        # ì‹¤ì œë¡œëŠ” OCRì´ í•„ìš”í•˜ì§€ë§Œ, ì¼ë‹¨ í˜ì´ì§€ ë²ˆí˜¸ë¡œ ì¶”ì •
        # ë³´í†µ ì¤‘ëŒ€ì„± í‰ê°€ëŠ” ë³´ê³ ì„œ ì¤‘ê°„ ë¶€ë¶„ì— ìœ„ì¹˜
        page_num = page["page_number"]
        total_pages = 50  # ì„ì‹œê°’
        
        # ì¤‘ê°„ 50% í˜ì´ì§€ ë²”ìœ„ì—ì„œ ì°¾ê¸°
        middle_start = int(total_pages * 0.3)
        middle_end = int(total_pages * 0.8)
        
        return middle_start <= page_num <= middle_end
    
    async def _is_materiality_page(self, page: Dict[str, Any]) -> bool:
        """Gemini Visionìœ¼ë¡œ ì¤‘ëŒ€ì„± í‰ê°€ í˜ì´ì§€ì¸ì§€ í™•ì¸"""
        prompt = """
        ì´ í˜ì´ì§€ê°€ ì§€ì†ê°€ëŠ¥ê²½ì˜ë³´ê³ ì„œì˜ ì¤‘ëŒ€ì„± í‰ê°€(Materiality Assessment) ì„¹ì…˜ì¸ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.
        
        ë‹¤ìŒ ìš”ì†Œë“¤ì„ í™•ì¸í•´ì£¼ì„¸ìš”:
        1. "ì¤‘ëŒ€ì„±", "materiality", "ì¤‘ìš”ë„" ë“±ì˜ ìš©ì–´
        2. ë§¤íŠ¸ë¦­ìŠ¤ ë˜ëŠ” ê·¸ë˜í”„ í˜•íƒœì˜ ë„í‘œ
        3. ì´í•´ê´€ê³„ì ê´€ì‹¬ë„/ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥ë„ ì¶•
        4. ESG ì´ìŠˆë“¤ì˜ ë‚˜ì—´
        
        ë‹¨ìˆœíˆ "ì˜ˆ" ë˜ëŠ” "ì•„ë‹ˆì˜¤"ë¡œë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
        """
        
        try:
            response = await self.gemini_client.analyze_image_with_text(
                image_base64=page["image_base64"],
                prompt=prompt,
                model_name="gemini-2.0-flash",
                max_tokens=10
            )
            
            return "ì˜ˆ" in response.get("content", "").strip().lower()
            
        except Exception as e:
            logger.warning(f"âš ï¸ í˜ì´ì§€ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return False
    
    async def _extract_materiality_issues(self, pages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì¤‘ëŒ€ì„± ì´ìŠˆ ì¶”ì¶œ"""
        all_issues = []
        
        for page in pages:
            try:
                logger.info(f"ğŸ¯ í˜ì´ì§€ {page['page_number']} ì¤‘ëŒ€ì„± ì´ìŠˆ ì¶”ì¶œ")
                issues = await self._extract_issues_from_page(page)
                all_issues.extend(issues)
                
            except Exception as e:
                logger.warning(f"âš ï¸ í˜ì´ì§€ {page['page_number']} ì´ìŠˆ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
                continue
        
        # ì¤‘ë³µ ì œê±° ë° ì •ì œ
        unique_issues = self._deduplicate_issues(all_issues)
        return unique_issues
    
    async def _extract_issues_from_page(self, page: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ë‹¨ì¼ í˜ì´ì§€ì—ì„œ ì¤‘ëŒ€ì„± ì´ìŠˆ ì¶”ì¶œ"""
        prompt = """
        ì´ ì§€ì†ê°€ëŠ¥ê²½ì˜ë³´ê³ ì„œ í˜ì´ì§€ì—ì„œ ì¤‘ëŒ€ì„± í‰ê°€ ì´ìŠˆë“¤ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
        
        ë‹¤ìŒ ì •ë³´ë¥¼ JSON ë°°ì—´ í˜•íƒœë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”:
        [
            {
                "issue_name": "ì´ìŠˆëª… (í•œêµ­ì–´)",
                "esg_category": "E" | "S" | "G",
                "stakeholder_interest": "ë†’ìŒ" | "ë³´í†µ" | "ë‚®ìŒ",
                "business_impact": "ë†’ìŒ" | "ë³´í†µ" | "ë‚®ìŒ",
                "priority": "ë†’ìŒ" | "ë³´í†µ" | "ë‚®ìŒ",
                "description": "ì´ìŠˆì— ëŒ€í•œ ê°„ë‹¨í•œ ì„¤ëª…"
            }
        ]
        
        ì£¼ì˜ì‚¬í•­:
        1. ëª…í™•í•œ ì´ìŠˆë§Œ ì¶”ì¶œí•˜ì„¸ìš”
        2. ì¤‘ë³µëœ ì´ìŠˆëŠ” ì œì™¸í•˜ì„¸ìš”
        3. ESG ì¹´í…Œê³ ë¦¬: E(í™˜ê²½), S(ì‚¬íšŒ), G(ì§€ë°°êµ¬ì¡°)
        4. ì •ë³´ê°€ ë¶ˆëª…í™•í•œ ê²½ìš° "ë³´í†µ"ìœ¼ë¡œ ì„¤ì •
        
        JSON í˜•íƒœë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
        """
        
        try:
            response = await self.gemini_client.analyze_image_with_text(
                image_base64=page["image_base64"],
                prompt=prompt,
                model_name="gemini-2.0-flash",
                max_tokens=2000
            )
            
            # JSON íŒŒì‹± ì‹œë„
            content = response.get("content", "").strip()
            
            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "[" in content and "]" in content:
                start = content.find("[")
                end = content.rfind("]") + 1
                content = content[start:end]
            
            issues = json.loads(content)
            logger.info(f"âœ… í˜ì´ì§€ {page['page_number']}ì—ì„œ {len(issues)}ê°œ ì´ìŠˆ ì¶”ì¶œ")
            
            # í˜ì´ì§€ ì •ë³´ ì¶”ê°€
            for issue in issues:
                issue["source_page"] = page["page_number"]
            
            return issues
            
        except json.JSONDecodeError as e:
            logger.warning(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
            return []
        except Exception as e:
            logger.error(f"âŒ ì´ìŠˆ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def _deduplicate_issues(self, issues: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì¤‘ë³µ ì´ìŠˆ ì œê±°"""
        seen_names = set()
        unique_issues = []
        
        for issue in issues:
            issue_name = issue.get("issue_name", "").strip().lower()
            if issue_name and issue_name not in seen_names:
                seen_names.add(issue_name)
                unique_issues.append(issue)
        
        logger.info(f"ğŸ”„ ì¤‘ë³µ ì œê±°: {len(issues)}ê°œ â†’ {len(unique_issues)}ê°œ")
        return unique_issues
    
    def _categorize_esg_issues(self, issues: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
        """ESG ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì´ìŠˆ ë¶„ë¥˜"""
        categorized = {
            "í™˜ê²½(E)": [],
            "ì‚¬íšŒ(S)": [],
            "ì§€ë°°êµ¬ì¡°(G)": [],
            "ê¸°íƒ€": []
        }
        
        for issue in issues:
            esg_category = issue.get("esg_category", "").upper()
            if esg_category == "E":
                categorized["í™˜ê²½(E)"].append(issue)
            elif esg_category == "S":
                categorized["ì‚¬íšŒ(S)"].append(issue)
            elif esg_category == "G":
                categorized["ì§€ë°°êµ¬ì¡°(G)"].append(issue)
            else:
                categorized["ê¸°íƒ€"].append(issue)
        
        return categorized 