# app/services/document_processing_service.py

import logging
import shutil
import uuid
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional
from fastapi import UploadFile, HTTPException
import time
from pathlib import Path
from datetime import datetime

from app.core.config import settings
from app.infrastructure.clients.cost_manager_client import CostManagerClient
from app.infrastructure.clients.gemini_client import GeminiClient
from app.domain.logic import (
    extract_materiality_issues_enhanced,  # ìƒˆë¡œìš´ ê°œì„ ëœ í•¨ìˆ˜
    detect_industry_from_text,
    calculate_overall_confidence
)

# ë‹¤ë¥¸ ì˜ì¡´ì„±ë“¤ (ì›ë˜ main.pyì—ì„œ importí•˜ë˜ ê²ƒë“¤)
# TODO: ì´ ë¶€ë¶„ë“¤ë„ ë‚˜ì¤‘ì— ë¦¬íŒ©í† ë§ ëŒ€ìƒ
try:
    from app.process_esg import ESGDocumentProcessor
except ImportError:
    # process_esgê°€ ì•„ì§ ë¦¬íŒ©í† ë§ë˜ì§€ ì•Šì€ ê²½ìš° ì„ì‹œ ì²˜ë¦¬
    ESGDocumentProcessor = None

logger = logging.getLogger(__name__)

class DocumentProcessingService:
    """ë¬¸ì„œ ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš°ë¥¼ ë‹´ë‹¹í•˜ëŠ” ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self, 
                 cost_manager: CostManagerClient,
                 gemini_client: GeminiClient):
        self.cost_manager = cost_manager
        self.gemini_client = gemini_client
        
        # ESG ë¬¸ì„œ ì²˜ë¦¬ê¸° ì´ˆê¸°í™” (ë‚˜ì¤‘ì— ì´ê²ƒë„ ì˜ì¡´ì„± ì£¼ì…ìœ¼ë¡œ ë³€ê²½ ì˜ˆì •)
        if ESGDocumentProcessor:
            self.processor = ESGDocumentProcessor(output_dir=str(settings.OUTPUT_DIR))
        else:
            self.processor = None
            logger.warning("ESGDocumentProcessorë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    def validate_file(self, file: UploadFile) -> None:
        """ì—…ë¡œë“œëœ íŒŒì¼ ê²€ì¦"""
        # íŒŒì¼ í¬ê¸° í™•ì¸
        if file.size and file.size > settings.MAX_FILE_SIZE:
            raise HTTPException(
                status_code=413,
                detail=f"íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. ìµœëŒ€ {settings.MAX_FILE_SIZE/1024/1024:.1f}MBê¹Œì§€ í—ˆìš©ë©ë‹ˆë‹¤."
            )
        
        # íŒŒì¼ í™•ì¥ì í™•ì¸
        if file.filename:
            extension = file.filename.split('.')[-1].lower()
            if extension not in settings.ALLOWED_EXTENSIONS:
                raise HTTPException(
                    status_code=400,
                    detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. í—ˆìš©ëœ í˜•ì‹: {', '.join(settings.ALLOWED_EXTENSIONS)}"
                )
    
    def check_usage_limit(self) -> None:
        """ì¼ì¼ ì‚¬ìš©ëŸ‰ ì œí•œ í™•ì¸"""
        can_proceed, message = self.cost_manager.check_limits()
        
        if not can_proceed:
            logger.warning(f"API ì‚¬ìš©ëŸ‰ ì œí•œ: {message}")
            raise HTTPException(status_code=429, detail=message)
        
        logger.info("API ì‚¬ìš©ëŸ‰ í™•ì¸ í†µê³¼")
    
    async def process_uploaded_file(self, file: UploadFile) -> Dict[str, Any]:
        """
        ì—…ë¡œë“œëœ íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ ì¤‘ëŒ€ì„± ì´ìŠˆë¥¼ ì¶”ì¶œí•˜ëŠ” ë©”ì¸ ì›Œí¬í”Œë¡œìš°
        
        Args:
            file: ì—…ë¡œë“œëœ íŒŒì¼
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬
        """
        logger.info(f"íŒŒì¼ ì—…ë¡œë“œ ì‹œì‘: {file.filename}")
        
        # 1. ì‚¬ì „ ê²€ì¦
        self.validate_file(file)
        self.check_usage_limit()
        
        # 2. ì„ì‹œ íŒŒì¼ ì €ì¥
        file_id = str(uuid.uuid4())
        file_extension = file.filename.split('.')[-1].lower()
        temp_filename = f"{file_id}.{file_extension}"
        temp_path = Path(settings.UPLOAD_DIR) / temp_filename
        
        try:
            # íŒŒì¼ ì €ì¥
            with open(temp_path, "wb") as buffer:
                shutil.copyfileobj(file.file, buffer)
            
            logger.info(f"íŒŒì¼ ì €ì¥ ì™„ë£Œ: {temp_path}")
            
            # 3. ë¬¸ì„œ ì²˜ë¦¬
            if file_extension == "pdf":
                return await self._process_pdf(temp_path, file.filename, file_id)
            else:
                # ì´ë¯¸ì§€ ì²˜ë¦¬ëŠ” ì¶”í›„ êµ¬í˜„
                raise HTTPException(
                    status_code=501,
                    detail="ì´ë¯¸ì§€ ì²˜ë¦¬ ê¸°ëŠ¥ì€ í˜„ì¬ ê°œë°œ ì¤‘ì…ë‹ˆë‹¤. PDF íŒŒì¼ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”."
                )
                
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise HTTPException(
                status_code=500,
                detail=f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            )
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if temp_path.exists():
                temp_path.unlink()
                logger.info(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ: {temp_path}")
    
    async def process_document(self, file_path: str) -> Dict[str, Any]:
        """
        ğŸš€ ê°œì„ ëœ ë¬¸ì„œ ì²˜ë¦¬ - ìƒˆë¡œìš´ ë²”ìš© í‚¤ì›Œë“œ ì‚¬ì „ í™œìš©
        """
        logger.info(f"ğŸ”µ ê°œì„ ëœ ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘: {file_path}")
        start_time = time.time()
        
        try:
            # 1ì°¨: FAST ì „ëµìœ¼ë¡œ ì‹œë„ (ê°€ì¥ ë¹ ë¦„)
            logger.info("ğŸ”µ 1ì°¨: FAST ì „ëµìœ¼ë¡œ ì²˜ë¦¬ ì‹œë„")
            elements = self._process_pdf_fast(file_path)
            
            if not elements or len(elements) < 3:
                # 2ì°¨: ìµœì†Œí•œì˜ OCRìœ¼ë¡œ ì‹œë„
                logger.info("ğŸ”µ 2ì°¨: ê²½ëŸ‰ OCR ì „ëµìœ¼ë¡œ ì²˜ë¦¬ ì‹œë„")
                elements = self._process_pdf_lightweight_ocr(file_path)
            
            if not elements:
                raise HTTPException(
                    status_code=422,
                    detail="ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                )
            
            logger.info(f"âœ… ì´ {len(elements)}ê°œ ìš”ì†Œ ì¶”ì¶œ ì™„ë£Œ")
            
            # ğŸ“Š ì—…ì¢… ìë™ ê°ì§€
            full_text = " ".join([str(elem) for elem in elements[:50]])  # ì²˜ìŒ 50ê°œ ìš”ì†Œë¡œ ì—…ì¢… ê°ì§€
            detected_industry = detect_industry_from_text(full_text)
            logger.info(f"ğŸ­ ê°ì§€ëœ ì—…ì¢…: {detected_industry}")
            
            # ë¬¸ì„œ êµ¬ì¡° ë¶„ì„
            structure = self._analyze_structure_simple(elements)
            
            # ESG ë‚´ìš© ì¶”ì¶œ
            esg_content = self._extract_esg_simple(elements)
            
            # ğŸ¯ ê°œì„ ëœ ì¤‘ëŒ€ì„± ì´ìŠˆ ì¶”ì¶œ (ìƒˆë¡œìš´ ë²”ìš© í‚¤ì›Œë“œ ì‚¬ì „ ì‚¬ìš©)
            materiality_analysis = extract_materiality_issues_enhanced(elements)
            
            processing_time = time.time() - start_time
            logger.info(f"â±ï¸ ì´ ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
            
            # ğŸ“ˆ ê°œì„ ëœ ê²°ê³¼ êµ¬ì„±
            result = {
                "file_info": {
                    "filename": Path(file_path).name,
                    "file_id": Path(file_path).stem,
                    "processed_at": datetime.now().isoformat(),
                    "processing_time": f"{processing_time:.2f}ì´ˆ"
                },
                "document_analysis": {
                    "total_elements": structure["total_elements"],
                    "page_count": structure["page_count"],
                    "titles_found": len(structure["titles"]),
                    "tables_found": len(structure["tables"])
                },
                "industry_analysis": {
                    "detected_industry": materiality_analysis.get("detected_industry", detected_industry),
                    "confidence": "ë†’ìŒ" if materiality_analysis.get("detected_industry", detected_industry) != "ê¸°íƒ€" else "ë‚®ìŒ",
                    "keywords_used": "ì—…ì¢…ë³„ íŠ¹í™” í‚¤ì›Œë“œ" if materiality_analysis.get("detected_industry", detected_industry) != "ê¸°íƒ€" else "ë²”ìš© í‚¤ì›Œë“œ"
                },
                "materiality_issues": materiality_analysis.get("issues", []),
                "extraction_confidence": materiality_analysis.get("overall_confidence", {
                    "level": "ì¤‘ê°„",
                    "score": 0.5,
                    "details": {}
                }),
                "analysis_summary": {
                    "ì´_ì´ìŠˆ_ìˆ˜": len(materiality_analysis.get("issues", [])),
                    "ë†’ì€_ì‹ ë¢°ë„_ì´ìŠˆ": len([i for i in materiality_analysis.get("issues", []) if i.get("confidence", 0) >= 0.7]),
                    "í™˜ê²½_ì´ìŠˆ": len([i for i in materiality_analysis.get("issues", []) if i.get("category", "").startswith("í™˜ê²½")]),
                    "ì‚¬íšŒ_ì´ìŠˆ": len([i for i in materiality_analysis.get("issues", []) if i.get("category", "").startswith("ì‚¬íšŒ")]),
                    "ì§€ë°°êµ¬ì¡°_ì´ìŠˆ": len([i for i in materiality_analysis.get("issues", []) if i.get("category", "").startswith("ì§€ë°°êµ¬ì¡°")]),
                    "ì´ìŠˆ_ë‹¤ì–‘ì„±": materiality_analysis.get("overall_confidence", {}).get("details", {}).get("issue_diversity", 0)
                },
                "esg_content_summary": {
                    category: len(contents) 
                    for category, contents in esg_content.items()
                },
                "extraction_method": "enhanced_universal_keywords",
                "version": "2.0"
            }
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            raise HTTPException(
                status_code=500,
                detail=f"ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            )
    
    async def process_document_with_vision(self, file_path: str) -> Dict[str, Any]:
        """
        Gemini Vision API ê¸°ë°˜ ë¬¸ì„œ ì²˜ë¦¬
        """
        logger.info(f"ğŸ” Gemini Vision ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘: {file_path}")
        
        try:
            # Gemini Vision ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
            from app.services.gemini_vision_processor import GeminiVisionDocumentProcessor
            from app.infrastructure.clients.pdf_converter import PDFConverter
            
            pdf_converter = PDFConverter(dpi=200)
            vision_processor = GeminiVisionDocumentProcessor(
                gemini_client=self.gemini_client,
                pdf_converter=pdf_converter
            )
            
            # Vision APIë¡œ ì²˜ë¦¬
            result = await vision_processor.process_document(file_path)
            
            # ë¹„ìš© ê¸°ë¡
            self.cost_manager.record_api_call("gemini_vision", 1, 1000, 0.01)  # ì„ì‹œ ë¹„ìš©
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ Gemini Vision ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            raise HTTPException(
                status_code=500,
                detail=f"Gemini Vision ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            )
    
    def _process_pdf_fast(self, file_path: str) -> List:
        """ë¹ ë¥¸ PDF ì²˜ë¦¬ - FAST ì „ëµ"""
        try:
            from unstructured.partition.pdf import partition_pdf
            
            elements = partition_pdf(
                filename=file_path,
                strategy="fast",  # ê°€ì¥ ë¹ ë¥¸ ì „ëµ
                infer_table_structure=False,  # í…Œì´ë¸” ì²˜ë¦¬ ë¹„í™œì„±í™”
                include_page_breaks=False,    # í˜ì´ì§€ êµ¬ë¶„ ë¹„í™œì„±í™”
                extract_images_in_pdf=False,  # ì´ë¯¸ì§€ ì¶”ì¶œ ë¹„í™œì„±í™”
                languages=["kor"]  # í•œêµ­ì–´ë§Œ
            )
            
            logger.info(f"ğŸ”µ FAST ì „ëµ: {len(elements)}ê°œ ìš”ì†Œ ì¶”ì¶œ")
            return elements
            
        except Exception as e:
            logger.warning(f"ğŸ”µ FAST ì „ëµ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def _process_pdf_lightweight_ocr(self, file_path: str) -> List:
        """ê²½ëŸ‰ OCR ì²˜ë¦¬"""
        try:
            from unstructured.partition.pdf import partition_pdf
            
            elements = partition_pdf(
                filename=file_path,
                strategy="ocr_only",  # OCRë§Œ ì‚¬ìš©
                infer_table_structure=False,  # í…Œì´ë¸” ì²˜ë¦¬ ë¹„í™œì„±í™”
                include_page_breaks=False,    # í˜ì´ì§€ êµ¬ë¶„ ë¹„í™œì„±í™”
                extract_images_in_pdf=False,  # ì´ë¯¸ì§€ ì¶”ì¶œ ë¹„í™œì„±í™”
                languages=["kor"],  # í•œêµ­ì–´ë§Œ
                max_pages=5  # ìµœëŒ€ 5í˜ì´ì§€ë§Œ ì²˜ë¦¬
            )
            
            logger.info(f"ğŸ”µ ê²½ëŸ‰ OCR: {len(elements)}ê°œ ìš”ì†Œ ì¶”ì¶œ")
            return elements
            
        except Exception as e:
            logger.warning(f"ğŸ”µ ê²½ëŸ‰ OCR ì‹¤íŒ¨: {str(e)}")
            return []
    
    def _analyze_structure_simple(self, elements: List) -> Dict[str, Any]:
        """ê°„ë‹¨í•œ ë¬¸ì„œ êµ¬ì¡° ë¶„ì„"""
        structure = {
            "total_elements": len(elements),
            "titles": [],
            "tables": [],
            "page_count": 1
        }
        
        for element in elements:
            # ì œëª© ìš”ì†Œ ìˆ˜ì§‘
            if hasattr(element, 'category') and element.category == "Title":
                structure["titles"].append(element.text)
            
            # í…Œì´ë¸” ìš”ì†Œ ìˆ˜ì§‘
            elif hasattr(element, 'category') and element.category == "Table":
                structure["tables"].append(element.text[:100])
            
            # í˜ì´ì§€ ìˆ˜ ê³„ì‚°
            if hasattr(element, 'metadata') and hasattr(element.metadata, 'page_number') and element.metadata.page_number:
                structure["page_count"] = max(structure["page_count"], element.metadata.page_number)
        
        return structure
    
    def _extract_esg_simple(self, elements: List) -> Dict[str, List[str]]:
        """ê°„ë‹¨í•œ ESG í‚¤ì›Œë“œ ì¶”ì¶œ"""
        esg_keywords = {
            "í™˜ê²½(E)": ["ê¸°í›„ë³€í™”", "íƒ„ì†Œ", "ì—ë„ˆì§€", "í™˜ê²½"],
            "ì‚¬íšŒ(S)": ["ì•ˆì „", "ì§ì›", "ì¸ê¶Œ", "ì§€ì—­ì‚¬íšŒ"],
            "ì§€ë°°êµ¬ì¡°(G)": ["ì´ì‚¬íšŒ", "ì§€ë°°êµ¬ì¡°", "ìœ¤ë¦¬", "íˆ¬ëª…ì„±"],
            "ì¤‘ëŒ€ì„±í‰ê°€": ["ì¤‘ëŒ€ì„±", "ì´ìŠˆ", "ì¤‘ìš”ë„", "ì´í•´ê´€ê³„ì"]
        }
        
        extracted_content = {category: [] for category in esg_keywords.keys()}
        
        for element in elements:
            element_text = element.text if hasattr(element, 'text') else str(element)
            
            for category, keywords in esg_keywords.items():
                for keyword in keywords:
                    if keyword in element_text:
                        content = element_text[:200]  # 200ìë¡œ ì œí•œ
                        if content not in extracted_content[category]:
                            extracted_content[category].append(content)
                            break  # ì²« ë²ˆì§¸ í‚¤ì›Œë“œ ë§¤ì¹˜ ì‹œ ì¤‘ë‹¨
        
        return extracted_content
    
    async def _process_pdf(self, temp_path: Path, filename: str, file_id: str) -> Dict[str, Any]:
        """PDF íŒŒì¼ ì²˜ë¦¬ ë¡œì§ (í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ë²•)"""
        if not self.processor:
            raise HTTPException(
                status_code=500,
                detail="ë¬¸ì„œ ì²˜ë¦¬ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            )
        
        # 1ì°¨: ì¼ë°˜ ê³ í•´ìƒë„ ì²˜ë¦¬
        logger.info("1ì°¨: ê³ í•´ìƒë„ PDF ì²˜ë¦¬ ì‹œì‘")
        elements = self.processor.process_pdf(str(temp_path), use_ocr=False)
        
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ OCR ì‹œë„
        if not elements or len(elements) == 0:
            logger.info("2ì°¨: OCRì„ ì‚¬ìš©í•œ PDF ì²˜ë¦¬ ì‹œì‘")
            elements = self.processor.process_pdf(str(temp_path), use_ocr=True)
        
        # OCRë„ ì‹¤íŒ¨í•œ ê²½ìš° Gemini Vision API ì‹œë„ (í–¥í›„ êµ¬í˜„)
        if not elements or len(elements) == 0:
            logger.warning("Unstructured ì²˜ë¦¬ ì‹¤íŒ¨, Gemini Vision API ì‚¬ìš© í•„ìš”")
            # TODO: Gemini Vision API êµ¬í˜„
            raise HTTPException(
                status_code=422,
                detail="PDFì—ì„œ ë‚´ìš©ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì´ ì†ìƒë˜ì—ˆê±°ë‚˜ í…ìŠ¤íŠ¸ê°€ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Gemini Vision APIë¥¼ ì‹œë„í•´ë³´ì„¸ìš”."
            )
        
        # ë¬¸ì„œ êµ¬ì¡° ë¶„ì„
        structure = self.processor.analyze_document_structure(elements)
        
        # ESG ë‚´ìš© ì¶”ì¶œ
        esg_content = self.processor.extract_esg_keywords(elements)
        
        # 1ì°¨: Unstructured ê¸°ë°˜ ì¤‘ëŒ€ì„± ì´ìŠˆ ì¶”ì¶œ (ë„ë©”ì¸ ë¡œì§ ì‚¬ìš©)
        unstructured_analysis = extract_materiality_issues_enhanced(elements)
        unstructured_issues = unstructured_analysis.get("issues", [])
        
        # 2ì°¨: Gemini AI ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„ì„ (ì„ì‹œ ë¹„í™œì„±í™”)
        gemini_result = {"success": False}
        extraction_method = "unstructured_only"
        
        # ì„ì‹œë¡œ Gemini API ë¹„í™œì„±í™” (ë¸”ë¡œí‚¹ ì´ìŠˆ í•´ê²°)
        if False and self.gemini_client.is_available() and len(unstructured_issues) < 5:
            # unstructured ê²°ê³¼ê°€ ë¶€ì¡±í•œ ê²½ìš°ì—ë§Œ Gemini í™œìš©
            full_text = "\n".join([el.text for el in elements if hasattr(el, 'text')])
            logger.info("Gemini APIë¥¼ ì‚¬ìš©í•œ ì¶”ê°€ ë¶„ì„ ì‹œì‘")
            
            success, gemini_result = await self.gemini_client.extract_issues_from_text(
                full_text[:5000], 
                settings.GEMINI_MODEL, 
                settings.GEMINI_MAX_TOKENS
            )
            
            if not success:
                logger.warning(f"Gemini ë¶„ì„ ì‹¤íŒ¨: {gemini_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
        
        # ê²°ê³¼ ë³‘í•©
        if gemini_result.get("success"):
            final_issues = self.gemini_client.merge_extraction_results(unstructured_issues, gemini_result)
            extraction_method = "hybrid"
        else:
            final_issues = unstructured_issues
        
        # ì²˜ë¦¬ ì™„ë£Œ í›„ ì‚¬ìš©ëŸ‰ ê¸°ë¡ (unstructured ì²˜ë¦¬ëŠ” ë¬´ë£Œ)
        self.cost_manager.record_api_call("unstructured", 0, 0, 0.0)
        
        # ê²°ê³¼ êµ¬ì„±
        result = {
            "file_info": {
                "filename": filename,
                "file_id": file_id,
                "processed_at": datetime.now().isoformat()
            },
            "document_analysis": {
                "total_elements": structure["total_elements"],
                "page_count": structure["page_count"],
                "titles_found": len(structure["titles"]),
                "tables_found": len(structure["tables"])
            },
            "materiality_issues": final_issues,
            "esg_content_summary": {
                category: len(contents) 
                for category, contents in esg_content.items()
            },
            "extraction_method": extraction_method,
            "extraction_confidence": calculate_overall_confidence(final_issues, structure),
            "gemini_metadata": gemini_result.get("metadata") if gemini_result.get("success") else None
        }
        
        logger.info(f"ì²˜ë¦¬ ì™„ë£Œ: {len(final_issues)}ê°œ ì´ìŠˆ ì¶”ì¶œ ({extraction_method})")
        return result
    
    def get_usage_summary(self) -> Dict[str, Any]:
        """í˜„ì¬ ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© í™•ì¸"""
        return self.cost_manager.get_usage_summary()
    
    def reset_daily_usage(self) -> Dict[str, Any]:
        """ì˜¤ëŠ˜ ì‚¬ìš©ëŸ‰ ë¦¬ì…‹ (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©)"""
        self.cost_manager.reset_daily_usage()
        
        return {
            "message": "ì˜¤ëŠ˜ ì‚¬ìš©ëŸ‰ì´ ë¦¬ì…‹ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "timestamp": datetime.now().isoformat()
        }
    
    def get_health_status(self) -> Dict[str, Any]:
        """í—¬ìŠ¤ ì²´í¬ ì •ë³´ ë°˜í™˜"""
        usage_info = self.cost_manager.get_usage_summary()
        today_usage = usage_info["today"]
        
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "daily_usage": today_usage["requests_count"],
            "daily_limit": usage_info["daily_limits"]["requests"],
            "estimated_cost": f"${today_usage['estimated_cost']:.4f}",
            "cost_limit": f"${usage_info['daily_limits']['cost']:.2f}",
            "gemini_available": self.gemini_client.is_available()
        }
