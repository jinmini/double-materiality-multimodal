# app/services/document_processing_service.py

import logging
import shutil
import uuid
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional
from fastapi import UploadFile, HTTPException
import time
from pathlib import Path
from datetime import datetime

from app.core.config import settings
from app.infrastructure.clients.cost_manager_client import CostManagerClient
from app.infrastructure.clients.gemini_client import GeminiClient
from app.domain.logic import (
    extract_materiality_issues_enhanced,  # ìƒˆë¡œìš´ ê°œì„ ëœ í•¨ìˆ˜
    detect_industry_from_text,
    calculate_overall_confidence
)

# ESGDocumentProcessor ì œê±° ì™„ë£Œ - process_esg.py ì‚­ì œë¨

logger = logging.getLogger(__name__)

class DocumentProcessingService:
    """ë¬¸ì„œ ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš°ë¥¼ ë‹´ë‹¹í•˜ëŠ” ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self, 
                 cost_manager: CostManagerClient,
                 gemini_client: GeminiClient):
        self.cost_manager = cost_manager
        self.gemini_client = gemini_client
    
    def validate_file(self, file: UploadFile) -> None:
        """ì—…ë¡œë“œëœ íŒŒì¼ ê²€ì¦"""
        # íŒŒì¼ í¬ê¸° í™•ì¸
        if file.size and file.size > settings.MAX_FILE_SIZE:
            raise HTTPException(
                status_code=413,
                detail=f"íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. ìµœëŒ€ {settings.MAX_FILE_SIZE/1024/1024:.1f}MBê¹Œì§€ í—ˆìš©ë©ë‹ˆë‹¤."
            )
        
        # íŒŒì¼ í™•ì¥ì í™•ì¸
        if file.filename:
            extension = file.filename.split('.')[-1].lower()
            if extension not in settings.ALLOWED_EXTENSIONS:
                raise HTTPException(
                    status_code=400,
                    detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. í—ˆìš©ëœ í˜•ì‹: {', '.join(settings.ALLOWED_EXTENSIONS)}"
                )
    
    def check_usage_limit(self) -> None:
        """ì¼ì¼ ì‚¬ìš©ëŸ‰ ì œí•œ í™•ì¸"""
        can_proceed, message = self.cost_manager.check_limits()
        
        if not can_proceed:
            logger.warning(f"API ì‚¬ìš©ëŸ‰ ì œí•œ: {message}")
            raise HTTPException(status_code=429, detail=message)
        
        logger.info("API ì‚¬ìš©ëŸ‰ í™•ì¸ í†µê³¼")
    
    async def save_uploaded_file_and_process_with_vision(self, file: UploadFile) -> Dict[str, Any]:
        """
        Vision APIìš© íŒŒì¼ ì €ì¥ ë° ì²˜ë¦¬ í—¬í¼ ë©”ì„œë“œ
        """
        logger.info(f"ğŸ” Vision API íŒŒì¼ ì—…ë¡œë“œ ì‹œì‘: {file.filename}")
        
        # 1. ì‚¬ì „ ê²€ì¦
        self.validate_file(file)
        self.check_usage_limit()
        
        # 2. ì„ì‹œ íŒŒì¼ ì €ì¥
        file_id = str(uuid.uuid4())
        file_extension = file.filename.split('.')[-1].lower()
        temp_filename = f"{file_id}.{file_extension}"
        temp_path = Path(settings.UPLOAD_DIR) / temp_filename
        
        try:
            # íŒŒì¼ ì €ì¥
            with open(temp_path, "wb") as buffer:
                shutil.copyfileobj(file.file, buffer)
            
            logger.info(f"ğŸ” íŒŒì¼ ì €ì¥ ì™„ë£Œ: {temp_path}")
            
            # 3. Vision APIë¡œ ë¬¸ì„œ ì²˜ë¦¬
            if file_extension == "pdf":
                result = await self.process_document_with_vision(str(temp_path))
                # íŒŒì¼ ì •ë³´ ì—…ë°ì´íŠ¸
                result["file_info"]["filename"] = file.filename
                result["file_info"]["file_id"] = file_id
                return result
            else:
                raise HTTPException(
                    status_code=501,
                    detail="Vision APIëŠ” í˜„ì¬ PDF íŒŒì¼ë§Œ ì§€ì›í•©ë‹ˆë‹¤."
                )
                
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Vision API ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise HTTPException(
                status_code=500,
                detail=f"Vision API íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            )
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if temp_path.exists():
                temp_path.unlink()
                logger.info(f"ğŸ” ì„ì‹œ íŒŒì¼ ì‚­ì œ: {temp_path}")
    
    async def process_uploaded_file(self, file: UploadFile) -> Dict[str, Any]:
        """
        ì—…ë¡œë“œëœ íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ ì¤‘ëŒ€ì„± ì´ìŠˆë¥¼ ì¶”ì¶œí•˜ëŠ” ë©”ì¸ ì›Œí¬í”Œë¡œìš°
        
        Args:
            file: ì—…ë¡œë“œëœ íŒŒì¼
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬
        """
        logger.info(f"íŒŒì¼ ì—…ë¡œë“œ ì‹œì‘: {file.filename}")
        
        # 1. ì‚¬ì „ ê²€ì¦
        self.validate_file(file)
        self.check_usage_limit()
        
        # 2. ì„ì‹œ íŒŒì¼ ì €ì¥
        file_id = str(uuid.uuid4())
        file_extension = file.filename.split('.')[-1].lower()
        temp_filename = f"{file_id}.{file_extension}"
        temp_path = Path(settings.UPLOAD_DIR) / temp_filename
        
        try:
            # íŒŒì¼ ì €ì¥
            with open(temp_path, "wb") as buffer:
                shutil.copyfileobj(file.file, buffer)
            
            logger.info(f"íŒŒì¼ ì €ì¥ ì™„ë£Œ: {temp_path}")
            
            # 3. ë¬¸ì„œ ì²˜ë¦¬
            if file_extension == "pdf":
                result = await self.process_document(str(temp_path))
                # íŒŒì¼ ì •ë³´ ì—…ë°ì´íŠ¸
                result["file_info"]["filename"] = file.filename
                result["file_info"]["file_id"] = file_id
                return result
            else:
                # ì´ë¯¸ì§€ ì²˜ë¦¬ëŠ” ì¶”í›„ êµ¬í˜„
                raise HTTPException(
                    status_code=501,
                    detail="ì´ë¯¸ì§€ ì²˜ë¦¬ ê¸°ëŠ¥ì€ í˜„ì¬ ê°œë°œ ì¤‘ì…ë‹ˆë‹¤. PDF íŒŒì¼ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”."
                )
                
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise HTTPException(
                status_code=500,
                detail=f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            )
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if temp_path.exists():
                temp_path.unlink()
                logger.info(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ: {temp_path}")
    
    async def process_document(self, file_path: str) -> Dict[str, Any]:
        """
        ğŸš€ ê°œì„ ëœ ë¬¸ì„œ ì²˜ë¦¬ - ìƒˆë¡œìš´ ë²”ìš© í‚¤ì›Œë“œ ì‚¬ì „ í™œìš©
        """
        logger.info(f"ğŸ”µ ê°œì„ ëœ ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘: {file_path}")
        start_time = time.time()
        
        try:
            # 1ì°¨: FAST ì „ëµìœ¼ë¡œ ì‹œë„ (ê°€ì¥ ë¹ ë¦„)
            logger.info("ğŸ”µ 1ì°¨: FAST ì „ëµìœ¼ë¡œ ì²˜ë¦¬ ì‹œë„")
            elements = self._process_pdf_fast(file_path)
            
            if not elements or len(elements) < 3:
                # 2ì°¨: ìµœì†Œí•œì˜ OCRìœ¼ë¡œ ì‹œë„
                logger.info("ğŸ”µ 2ì°¨: ê²½ëŸ‰ OCR ì „ëµìœ¼ë¡œ ì²˜ë¦¬ ì‹œë„")
                elements = self._process_pdf_lightweight_ocr(file_path)
            
            if not elements:
                raise HTTPException(
                    status_code=422,
                    detail="ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                )
            
            logger.info(f"âœ… ì´ {len(elements)}ê°œ ìš”ì†Œ ì¶”ì¶œ ì™„ë£Œ")
            
            # ğŸ“Š ì—…ì¢… ìë™ ê°ì§€
            full_text = " ".join([str(elem) for elem in elements[:50]])  # ì²˜ìŒ 50ê°œ ìš”ì†Œë¡œ ì—…ì¢… ê°ì§€
            detected_industry = detect_industry_from_text(full_text)
            logger.info(f"ğŸ­ ê°ì§€ëœ ì—…ì¢…: {detected_industry}")
            
            # ë¬¸ì„œ êµ¬ì¡° ë¶„ì„
            structure = self._analyze_structure_simple(elements)
            
            # ESG ë‚´ìš© ì¶”ì¶œ
            esg_content = self._extract_esg_simple(elements)
            
            # ğŸ¯ ê°œì„ ëœ ì¤‘ëŒ€ì„± ì´ìŠˆ ì¶”ì¶œ (ìƒˆë¡œìš´ ë²”ìš© í‚¤ì›Œë“œ ì‚¬ì „ ì‚¬ìš©)
            materiality_analysis = extract_materiality_issues_enhanced(elements)
            
            processing_time = time.time() - start_time
            logger.info(f"â±ï¸ ì´ ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
            
            # ğŸ“ˆ ê°œì„ ëœ ê²°ê³¼ êµ¬ì„±
            result = {
                "file_info": {
                    "filename": Path(file_path).name,
                    "file_id": Path(file_path).stem,
                    "processed_at": datetime.now().isoformat(),
                    "processing_time": f"{processing_time:.2f}ì´ˆ"
                },
                "document_analysis": {
                    "total_elements": structure["total_elements"],
                    "page_count": structure["page_count"],
                    "titles_found": len(structure["titles"]),
                    "tables_found": len(structure["tables"])
                },
                "industry_analysis": {
                    "detected_industry": materiality_analysis.get("detected_industry", detected_industry),
                    "confidence": "ë†’ìŒ" if materiality_analysis.get("detected_industry", detected_industry) != "ê¸°íƒ€" else "ë‚®ìŒ",
                    "keywords_used": "ì—…ì¢…ë³„ íŠ¹í™” í‚¤ì›Œë“œ" if materiality_analysis.get("detected_industry", detected_industry) != "ê¸°íƒ€" else "ë²”ìš© í‚¤ì›Œë“œ"
                },
                "materiality_issues": materiality_analysis.get("issues", []),
                "extraction_confidence": materiality_analysis.get("overall_confidence", {
                    "level": "ì¤‘ê°„",
                    "score": 0.5,
                    "details": {}
                }),
                "analysis_summary": {
                    "ì´_ì´ìŠˆ_ìˆ˜": len(materiality_analysis.get("issues", [])),
                    "ë†’ì€_ì‹ ë¢°ë„_ì´ìŠˆ": len([i for i in materiality_analysis.get("issues", []) if i.get("confidence", 0) >= 0.7]),
                    "í™˜ê²½_ì´ìŠˆ": len([i for i in materiality_analysis.get("issues", []) if i.get("category", "").startswith("í™˜ê²½")]),
                    "ì‚¬íšŒ_ì´ìŠˆ": len([i for i in materiality_analysis.get("issues", []) if i.get("category", "").startswith("ì‚¬íšŒ")]),
                    "ì§€ë°°êµ¬ì¡°_ì´ìŠˆ": len([i for i in materiality_analysis.get("issues", []) if i.get("category", "").startswith("ì§€ë°°êµ¬ì¡°")]),
                    "ì´ìŠˆ_ë‹¤ì–‘ì„±": materiality_analysis.get("overall_confidence", {}).get("details", {}).get("issue_diversity", 0)
                },
                "esg_content_summary": {
                    category: len(contents) 
                    for category, contents in esg_content.items()
                },
                "extraction_method": "enhanced_universal_keywords",
                "version": "2.0"
            }
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            raise HTTPException(
                status_code=500,
                detail=f"ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            )
    
    async def process_document_with_vision(self, file_path: str) -> Dict[str, Any]:
        """
        Gemini Vision API ê¸°ë°˜ ë¬¸ì„œ ì²˜ë¦¬ (íƒ€ì„ì•„ì›ƒ ì ìš©)
        """
        logger.info(f"ğŸ” Gemini Vision ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘: {file_path}")
        
        try:
            # Gemini Vision ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
            from app.services.gemini_vision_processor import GeminiVisionDocumentProcessor
            from app.infrastructure.clients.pdf_converter import PDFConverter
            import asyncio
            
            pdf_converter = PDFConverter(dpi=200)
            vision_processor = GeminiVisionDocumentProcessor(
                gemini_client=self.gemini_client,
                pdf_converter=pdf_converter
            )
            
            # ì „ì²´ ì²˜ë¦¬ì— 180ì´ˆ (3ë¶„) íƒ€ì„ì•„ì›ƒ ì ìš©
            logger.info("ğŸ” Vision API ì²˜ë¦¬ ì‹œì‘ (ìµœëŒ€ 3ë¶„ íƒ€ì„ì•„ì›ƒ)")
            result = await asyncio.wait_for(
                vision_processor.process_document(file_path),
                timeout=180.0
            )
            
            # ë¹„ìš© ê¸°ë¡
            self.cost_manager.record_api_call("gemini_vision", 1, 1000, 0.01)  # ì„ì‹œ ë¹„ìš©
            
            return result
            
        except asyncio.TimeoutError:
            logger.error("âŒ Gemini Vision ì „ì²´ ì²˜ë¦¬ íƒ€ì„ì•„ì›ƒ (3ë¶„ ì´ˆê³¼)")
            raise HTTPException(
                status_code=408,
                detail="ë¬¸ì„œ ì²˜ë¦¬ ì‹œê°„ì´ 3ë¶„ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ë” ì‘ì€ íŒŒì¼ì„ ì‚¬ìš©í•˜ê±°ë‚˜ ì¼ë°˜ ì—…ë¡œë“œë¥¼ ì‹œë„í•´ì£¼ì„¸ìš”."
            )
        except Exception as e:
            logger.error(f"âŒ Gemini Vision ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            raise HTTPException(
                status_code=500,
                detail=f"Gemini Vision ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            )
    
    def _process_pdf_fast(self, file_path: str) -> List:
        """ë¹ ë¥¸ PDF ì²˜ë¦¬ - FAST ì „ëµ"""
        try:
            from unstructured.partition.pdf import partition_pdf
            
            elements = partition_pdf(
                filename=file_path,
                strategy="hi_res",  # ê³ í•´ìƒë„ ì „ëµìœ¼ë¡œ ë³€ê²½
                infer_table_structure=True,  # í…Œì´ë¸” êµ¬ì¡° ì¸ì‹ í™œì„±í™”
                include_page_breaks=True,    # í˜ì´ì§€ êµ¬ë¶„ í™œì„±í™”
                extract_images_in_pdf=False,  # ì´ë¯¸ì§€ ì¶”ì¶œ ë¹„í™œì„±í™”
                languages=["eng"]  # ì˜ì–´ (í•œêµ­ì–´ OCR ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ë³€ê²½)
                # languages=["kor"]  # í•œêµ­ì–´ë§Œ (ì£¼ì„ì²˜ë¦¬)
            )
            
            logger.info(f"ğŸ”µ FAST ì „ëµ: {len(elements)}ê°œ ìš”ì†Œ ì¶”ì¶œ")
            return elements
            
        except Exception as e:
            logger.warning(f"ğŸ”µ FAST ì „ëµ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def _process_pdf_lightweight_ocr(self, file_path: str) -> List:
        """ê²½ëŸ‰ OCR ì²˜ë¦¬"""
        try:
            from unstructured.partition.pdf import partition_pdf
            
            elements = partition_pdf(
                filename=file_path,
                strategy="hi_res",  # ê³ í•´ìƒë„ ì „ëµìœ¼ë¡œ ë³€ê²½
                infer_table_structure=True,  # í…Œì´ë¸” êµ¬ì¡° ì¸ì‹ í™œì„±í™”
                include_page_breaks=True,    # í˜ì´ì§€ êµ¬ë¶„ í™œì„±í™”
                extract_images_in_pdf=False,  # ì´ë¯¸ì§€ ì¶”ì¶œ ë¹„í™œì„±í™”
                languages=["eng"],  # ì˜ì–´ (í•œêµ­ì–´ OCR ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ë³€ê²½)
                # languages=["kor"],  # í•œêµ­ì–´ë§Œ (ì£¼ì„ì²˜ë¦¬)
                max_pages=5  # ìµœëŒ€ 5í˜ì´ì§€ë§Œ ì²˜ë¦¬
            )
            
            logger.info(f"ğŸ”µ ê²½ëŸ‰ OCR: {len(elements)}ê°œ ìš”ì†Œ ì¶”ì¶œ")
            return elements
            
        except Exception as e:
            logger.warning(f"ğŸ”µ ê²½ëŸ‰ OCR ì‹¤íŒ¨: {str(e)}")
            return []
    
    def _analyze_structure_simple(self, elements: List) -> Dict[str, Any]:
        """ê°„ë‹¨í•œ ë¬¸ì„œ êµ¬ì¡° ë¶„ì„"""
        structure = {
            "total_elements": len(elements),
            "titles": [],
            "tables": [],
            "page_count": 1
        }
        
        for element in elements:
            # ì œëª© ìš”ì†Œ ìˆ˜ì§‘
            if hasattr(element, 'category') and element.category == "Title":
                structure["titles"].append(element.text)
            
            # í…Œì´ë¸” ìš”ì†Œ ìˆ˜ì§‘
            elif hasattr(element, 'category') and element.category == "Table":
                structure["tables"].append(element.text[:100])
            
            # í˜ì´ì§€ ìˆ˜ ê³„ì‚°
            if hasattr(element, 'metadata') and hasattr(element.metadata, 'page_number') and element.metadata.page_number:
                structure["page_count"] = max(structure["page_count"], element.metadata.page_number)
        
        return structure
    
    def _extract_esg_simple(self, elements: List) -> Dict[str, List[str]]:
        """ê°„ë‹¨í•œ ESG í‚¤ì›Œë“œ ì¶”ì¶œ"""
        esg_keywords = {
            "í™˜ê²½(E)": ["ê¸°í›„ë³€í™”", "íƒ„ì†Œ", "ì—ë„ˆì§€", "í™˜ê²½"],
            "ì‚¬íšŒ(S)": ["ì•ˆì „", "ì§ì›", "ì¸ê¶Œ", "ì§€ì—­ì‚¬íšŒ"],
            "ì§€ë°°êµ¬ì¡°(G)": ["ì´ì‚¬íšŒ", "ì§€ë°°êµ¬ì¡°", "ìœ¤ë¦¬", "íˆ¬ëª…ì„±"],
            "ì¤‘ëŒ€ì„±í‰ê°€": ["ì¤‘ëŒ€ì„±", "ì´ìŠˆ", "ì¤‘ìš”ë„", "ì´í•´ê´€ê³„ì"]
        }
        
        extracted_content = {category: [] for category in esg_keywords.keys()}
        
        for element in elements:
            element_text = element.text if hasattr(element, 'text') else str(element)
            
            for category, keywords in esg_keywords.items():
                for keyword in keywords:
                    if keyword in element_text:
                        content = element_text[:200]  # 200ìë¡œ ì œí•œ
                        if content not in extracted_content[category]:
                            extracted_content[category].append(content)
                            break  # ì²« ë²ˆì§¸ í‚¤ì›Œë“œ ë§¤ì¹˜ ì‹œ ì¤‘ë‹¨
        
        return extracted_content
    

    
    def get_usage_summary(self) -> Dict[str, Any]:
        """í˜„ì¬ ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© í™•ì¸"""
        return self.cost_manager.get_usage_summary()
    
    def reset_daily_usage(self) -> Dict[str, Any]:
        """ì˜¤ëŠ˜ ì‚¬ìš©ëŸ‰ ë¦¬ì…‹ (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©)"""
        self.cost_manager.reset_daily_usage()
        
        return {
            "message": "ì˜¤ëŠ˜ ì‚¬ìš©ëŸ‰ì´ ë¦¬ì…‹ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "timestamp": datetime.now().isoformat()
        }
    
    def get_health_status(self) -> Dict[str, Any]:
        """í—¬ìŠ¤ ì²´í¬ ì •ë³´ ë°˜í™˜"""
        usage_info = self.cost_manager.get_usage_summary()
        today_usage = usage_info["today"]
        
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "daily_usage": today_usage["requests_count"],
            "daily_limit": usage_info["daily_limits"]["requests"],
            "estimated_cost": f"${today_usage['estimated_cost']:.4f}",
            "cost_limit": f"${usage_info['daily_limits']['cost']:.2f}",
            "gemini_available": self.gemini_client.is_available()
        }
