# app/domain/logic.py

from typing import Dict, Any, List, Optional, Tuple
from app.domain.constants import (
    UNIVERSAL_ESG_ISSUES, 
    MATERIALITY_KEYWORDS, 
    AUTO_INDUSTRY_DETECTION,
    INDUSTRY_SPECIFIC_KEYWORDS,
    ISSUE_PRIORITY_WEIGHTS,
    # í•˜ìœ„ í˜¸í™˜ì„±
    ESG_KEYWORDS, 
    ISSUE_KEYWORDS
)

# ==============================================================================
# ğŸ­ ì—…ì¢… ìë™ ê°ì§€ í•¨ìˆ˜
# ==============================================================================

def detect_industry_from_text(text: str) -> str:
    """
    ë¬¸ì„œ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì—…ì¢…ì„ ìë™ìœ¼ë¡œ ê°ì§€í•©ë‹ˆë‹¤.
    
    Args:
        text: ë¶„ì„í•  í…ìŠ¤íŠ¸ (ì „ì²´ ë¬¸ì„œ ë‚´ìš© ë˜ëŠ” ì¼ë¶€)
        
    Returns:
        ê°ì§€ëœ ì—…ì¢…ëª… (ì˜ˆ: "ì „ë ¥", "ì œì¡°", "ê¸ˆìœµ" ë“±) ë˜ëŠ” "ê¸°íƒ€"
    """
    industry_scores = {}
    
    # ê° ì—…ì¢…ë³„ í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚°
    for industry, keywords in AUTO_INDUSTRY_DETECTION.items():
        score = 0
        for keyword in keywords:
            # í‚¤ì›Œë“œ ë¹ˆë„ì— ë”°ë¥¸ ì ìˆ˜ ê³„ì‚°
            count = text.count(keyword)
            if count > 0:
                # ğŸ”¥ ê°œì„ : í‚¤ì›Œë“œë³„ ê°€ì¤‘ì¹˜ ì ìš©
                if "ë°œì „" in keyword or "íšŒì‚¬" in keyword or "í•œêµ­" in keyword:
                    # íšŒì‚¬ëª…ì´ë‚˜ í•µì‹¬ ì—…ì¢… í‚¤ì›Œë“œì— ë†’ì€ ê°€ì¤‘ì¹˜
                    score += min(count * 5, 25)  # ìµœëŒ€ 25ì 
                elif len(keyword) >= 4:
                    # êµ¬ì²´ì ì¸ í‚¤ì›Œë“œ (4ê¸€ì ì´ìƒ)ì— ì¤‘ê°„ ê°€ì¤‘ì¹˜
                    score += min(count * 3, 15)  # ìµœëŒ€ 15ì 
                else:
                    # ì¼ë°˜ í‚¤ì›Œë“œì— ê¸°ë³¸ ê°€ì¤‘ì¹˜
                    score += min(count * 2, 10)  # ìµœëŒ€ 10ì 
        
        industry_scores[industry] = score
    
    # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì—…ì¢… ë°˜í™˜
    if industry_scores and max(industry_scores.values()) > 0:
        detected_industry = max(industry_scores, key=industry_scores.get)
        print(f"ğŸ­ ê°ì§€ëœ ì—…ì¢…: {detected_industry} (ì ìˆ˜: {industry_scores[detected_industry]})")
        
        # ğŸ”¥ ê°œì„ : ë””ë²„ê¹…ì„ ìœ„í•œ ìƒìœ„ 3ê°œ ì—…ì¢… ì ìˆ˜ ì¶œë ¥
        sorted_industries = sorted(industry_scores.items(), key=lambda x: x[1], reverse=True)[:3]
        print(f"ğŸ­ ì—…ì¢…ë³„ ì ìˆ˜: {sorted_industries}")
        
        return detected_industry
    
    return "ê¸°íƒ€"

# ==============================================================================
# ğŸ¯ ë™ì  í‚¤ì›Œë“œ ë§¤ì¹­ í•¨ìˆ˜
# ==============================================================================

def get_dynamic_keywords_for_issue(issue_name: str, industry: str = "ê¸°íƒ€") -> List[str]:
    """
    ì´ìŠˆì™€ ì—…ì¢…ì— ë§ëŠ” ë™ì  í‚¤ì›Œë“œ ëª©ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        issue_name: ESG ì´ìŠˆëª…
        industry: ì—…ì¢… (ìë™ ê°ì§€ëœ ê²°ê³¼)
        
    Returns:
        í•´ë‹¹ ì´ìŠˆì— ì í•©í•œ í‚¤ì›Œë“œ ëª©ë¡
    """
    keywords = []
    
    # 1. UNIVERSAL_ESG_ISSUESì—ì„œ ê¸°ë³¸ í‚¤ì›Œë“œ ì¶”ì¶œ
    for category, issues in UNIVERSAL_ESG_ISSUES.items():
        if issue_name in issues:
            issue_data = issues[issue_name]
            # Core í‚¤ì›Œë“œ ì¶”ê°€
            keywords.extend(issue_data["core_keywords"])
            # Advanced í‚¤ì›Œë“œ ì¶”ê°€
            keywords.extend(issue_data["advanced_keywords"])
            
            # 2. ì—…ì¢…ë³„ íŠ¹í™” í‚¤ì›Œë“œ ì¶”ê°€
            if industry in issue_data["industry_variants"]:
                keywords.extend(issue_data["industry_variants"][industry])
            break
    
    # 3. ì—…ì¢…ë³„ ë¹„ì¦ˆë‹ˆìŠ¤ í‚¤ì›Œë“œ ì¶”ê°€ (ê´€ë ¨ì„±ì´ ìˆëŠ” ê²½ìš°)
    if industry in INDUSTRY_SPECIFIC_KEYWORDS:
        industry_data = INDUSTRY_SPECIFIC_KEYWORDS[industry]
        # íŠ¹ì • ì´ìŠˆì™€ ê´€ë ¨ì„±ì´ ë†’ì€ ë¹„ì¦ˆë‹ˆìŠ¤ í‚¤ì›Œë“œ ì„ ë³„ ì¶”ê°€
        if issue_name in ["ê³ ê° ë° ì œí’ˆì±…ì„", "ê³µê¸‰ë§ ê´€ë¦¬"]:
            keywords.extend(industry_data["business_keywords"])
    
    # ì¤‘ë³µ ì œê±° ë° ë°˜í™˜
    return list(set(keywords))

# ==============================================================================
# ğŸ“Š ê°œì„ ëœ ì¤‘ëŒ€ì„± ì´ìŠˆ ì¶”ì¶œ ë¡œì§
# ==============================================================================

def extract_materiality_issues_enhanced(elements: List[Any]) -> Dict[str, Any]:
    """
    ë²”ìš© í‚¤ì›Œë“œ ì‚¬ì „ì„ í™œìš©í•œ ê°œì„ ëœ ì¤‘ëŒ€ì„± ì´ìŠˆ ì¶”ì¶œ í•¨ìˆ˜.
    ì—…ì¢… ìë™ ê°ì§€ì™€ ë™ì  í‚¤ì›Œë“œ ë§¤ì¹­ì„ ì§€ì›í•©ë‹ˆë‹¤.
    """
    # 1. ì „ì²´ í…ìŠ¤íŠ¸ ìˆ˜ì§‘ (ì—…ì¢… ê°ì§€ìš©)
    full_text = " ".join([getattr(element, 'text', str(element)) for element in elements])
    
    # 2. ì—…ì¢… ìë™ ê°ì§€
    detected_industry = detect_industry_from_text(full_text)
    
    # 3. ì´ìŠˆ ì¶”ì¶œ
    issues = []
    issue_confidence_scores = {}
    
    for element in elements:
        element_text = getattr(element, 'text', str(element))
        
        # ğŸ”¥ ê°œì„ : í•„í„°ë§ ì¡°ê±´ ì™„í™” - ESG ê´€ë ¨ í‚¤ì›Œë“œë§Œ ìˆì–´ë„ ì²˜ë¦¬
        esg_related = False
        
        # ì¤‘ëŒ€ì„± í‚¤ì›Œë“œ ì²´í¬
        if any(keyword in element_text for keyword in MATERIALITY_KEYWORDS):
            esg_related = True
        
        # ESG ê¸°ë³¸ í‚¤ì›Œë“œ ì²´í¬ (í™˜ê²½, ì‚¬íšŒ, ì§€ë°°êµ¬ì¡°)
        basic_esg_keywords = ["í™˜ê²½", "ì‚¬íšŒ", "ì§€ë°°êµ¬ì¡°", "ESG", "ì§€ì†ê°€ëŠ¥", "sustainability"]
        if any(keyword in element_text for keyword in basic_esg_keywords):
            esg_related = True
        
        # í…ìŠ¤íŠ¸ê°€ ì¶©ë¶„íˆ ê¸¸ê³  ì˜ë¯¸ê°€ ìˆëŠ” ê²½ìš° (20ì ì´ìƒ)
        if len(element_text.strip()) >= 20:
            esg_related = True
        
        if not esg_related:
            continue

        # ê° ESG ì´ìŠˆë³„ë¡œ ë§¤ì¹­ ê²€ì‚¬
        for category, category_issues in UNIVERSAL_ESG_ISSUES.items():
            for issue_name in category_issues.keys():
                # ë™ì  í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°
                dynamic_keywords = get_dynamic_keywords_for_issue(issue_name, detected_industry)
                
                # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
                matched_keywords = [kw for kw in dynamic_keywords if kw in element_text]
                
                if matched_keywords:
                    # ì‹ ë¢°ë„ ê³„ì‚°
                    confidence = calculate_enhanced_confidence(
                        element_text, issue_name, matched_keywords, 
                        dynamic_keywords, detected_industry
                    )
                    
                    # í˜ì´ì§€ ì •ë³´ ì¶”ì¶œ
                    page_number = getattr(element.metadata, 'page_number', None) if hasattr(element, 'metadata') else None
                    
                    issue = {
                        "issue_id": len(issues) + 1,
                        "category": category.split("(")[0],  # "í™˜ê²½(E)" -> "í™˜ê²½"
                        "issue_name": issue_name,
                        "content": element_text[:500],
                        "matched_keywords": matched_keywords,
                        "page_number": page_number,
                        "element_type": type(element).__name__,
                        "confidence": confidence,
                        "industry": detected_industry
                    }
                    
                    issues.append(issue)
                    
                    # ì´ìŠˆë³„ ìµœê³  ì‹ ë¢°ë„ ì¶”ì 
                    if issue_name not in issue_confidence_scores or confidence > issue_confidence_scores[issue_name]:
                        issue_confidence_scores[issue_name] = confidence

    # 4. ì¤‘ë³µ ì œê±° ë° ì •ë ¬
    unique_issues = remove_duplicate_issues(issues)
    unique_issues.sort(key=lambda x: x["confidence"], reverse=True)
    
    # 5. ì—…ì¢…ë³„ ìš°ì„ ìˆœìœ„ ì ìš©
    prioritized_issues = apply_industry_priority(unique_issues, detected_industry)
    
    # 6. ê²°ê³¼ êµ¬ì„±
    result = {
        "detected_industry": detected_industry,
        "total_issues_found": len(prioritized_issues),
        "issues": prioritized_issues[:20],  # ìƒìœ„ 20ê°œ
        "overall_confidence": calculate_overall_confidence_enhanced(
            prioritized_issues, issue_confidence_scores, detected_industry
        ),
        "industry_priority_applied": True
    }
    
    return result

def calculate_enhanced_confidence(
    text: str, 
    issue_name: str, 
    matched_keywords: List[str], 
    all_keywords: List[str], 
    industry: str
) -> float:
    """ê°œì„ ëœ ì‹ ë¢°ë„ ê³„ì‚° í•¨ìˆ˜"""
    confidence = 0.0
    
    # 1. ê¸°ë³¸ í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ (0~0.5)
    keyword_ratio = len(matched_keywords) / len(all_keywords) if all_keywords else 0
    confidence += keyword_ratio * 0.5
    
    # 2. ì •í™•í•œ ì´ìŠˆëª… ë§¤ì¹­ ë³´ë„ˆìŠ¤ (0.3)
    if issue_name in text:
        confidence += 0.3
    
    # 3. ì¤‘ëŒ€ì„± ì»¨í…ìŠ¤íŠ¸ ë³´ë„ˆìŠ¤ (0.2)
    materiality_indicators = ["ì¤‘ëŒ€ì„±", "materiality", "í•µì‹¬ì´ìŠˆ", "ìš°ì„ ìˆœìœ„"]
    if any(indicator in text for indicator in materiality_indicators):
        confidence += 0.2
    
    # 4. í‘œ/ë§¤íŠ¸ë¦­ìŠ¤ í˜•ì‹ ë³´ë„ˆìŠ¤ (0.15)
    table_indicators = ["â”‚", "â”€", "í‘œ", "ë§¤íŠ¸ë¦­ìŠ¤", "ìˆœìœ„", "ë†’ìŒ", "ë³´í†µ", "ë‚®ìŒ"]
    if any(indicator in text for indicator in table_indicators):
        confidence += 0.15
    
    # 5. ì—…ì¢…ë³„ ê°€ì¤‘ì¹˜ ì ìš© (0~0.1)
    if industry in ISSUE_PRIORITY_WEIGHTS:
        issue_weight = ISSUE_PRIORITY_WEIGHTS[industry].get(issue_name, 0)
        confidence += issue_weight * 0.1
    
    # 6. ê³ í’ˆì§ˆ í‚¤ì›Œë“œ ë³´ë„ˆìŠ¤ (0.1)
    high_quality_keywords = ["í‰ê°€", "ê´€ë¦¬", "ì „ëµ", "ê°œì„ ", "ëª©í‘œ", "ì„±ê³¼"]
    if any(kw in matched_keywords for kw in high_quality_keywords):
        confidence += 0.1
    
    return min(confidence, 1.0)

def remove_duplicate_issues(issues: List[Dict]) -> List[Dict]:
    """ì¤‘ë³µ ì´ìŠˆ ì œê±°"""
    seen_issues = {}
    unique_issues = []
    
    for issue in issues:
        key = f"{issue['issue_name']}_{issue['page_number']}"
        
        if key not in seen_issues or issue['confidence'] > seen_issues[key]['confidence']:
            seen_issues[key] = issue
    
    return list(seen_issues.values())

def apply_industry_priority(issues: List[Dict], industry: str) -> List[Dict]:
    """ì—…ì¢…ë³„ ìš°ì„ ìˆœìœ„ ê°€ì¤‘ì¹˜ ì ìš©"""
    if industry not in ISSUE_PRIORITY_WEIGHTS:
        return issues
    
    weights = ISSUE_PRIORITY_WEIGHTS[industry]
    
    for issue in issues:
        issue_name = issue['issue_name']
        if issue_name in weights:
            # ê¸°ì¡´ ì‹ ë¢°ë„ì— ì—…ì¢…ë³„ ê°€ì¤‘ì¹˜ë¥¼ ê³±í•˜ì—¬ ìµœì¢… ì ìˆ˜ ê³„ì‚°
            priority_weight = weights[issue_name]
            issue['priority_score'] = issue['confidence'] * (1 + priority_weight)
            issue['industry_weight'] = priority_weight
        else:
            issue['priority_score'] = issue['confidence'] * 1.1  # ê¸°íƒ€ ì´ìŠˆëŠ” ì•½ê°„ì˜ ë³´ë„ˆìŠ¤ë§Œ
            issue['industry_weight'] = 0.1
    
    # ìš°ì„ ìˆœìœ„ ì ìˆ˜ë¡œ ì¬ì •ë ¬
    issues.sort(key=lambda x: x['priority_score'], reverse=True)
    return issues

def calculate_overall_confidence_enhanced(
    issues: List[Dict], 
    issue_scores: Dict[str, float], 
    industry: str
) -> Dict[str, Any]:
    """ê°œì„ ëœ ì „ì²´ ì‹ ë¢°ë„ ê³„ì‚°"""
    if not issues:
        return {
            "score": 0.0, 
            "level": "ë‚®ìŒ", 
            "reason": "ì´ìŠˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ",
            "industry": industry
        }
    
    # ê¸°ë³¸ í‰ê·  ì‹ ë¢°ë„
    avg_confidence = sum(issue["confidence"] for issue in issues) / len(issues)
    
    # ì—…ì¢… ê°ì§€ ë³´ë„ˆìŠ¤
    industry_bonus = 0.1 if industry != "ê¸°íƒ€" else 0
    
    # ì´ìŠˆ ë‹¤ì–‘ì„± ë³´ë„ˆìŠ¤ (ë” ë§ì€ ì´ìŠˆ ì¹´í…Œê³ ë¦¬ë¥¼ ë°œê²¬í• ìˆ˜ë¡ ì¢‹ìŒ)
    unique_categories = len(set(issue["category"] for issue in issues))
    diversity_bonus = min(unique_categories * 0.05, 0.15)
    
    # ê³ ì‹ ë¢°ë„ ì´ìŠˆ ë¹„ìœ¨
    high_confidence_issues = len([i for i in issues if i["confidence"] > 0.7])
    quality_bonus = (high_confidence_issues / len(issues)) * 0.1
    
    final_score = min(1.0, avg_confidence + industry_bonus + diversity_bonus + quality_bonus)
    
    # ì‹ ë¢°ë„ ë ˆë²¨ ê²°ì •
    if final_score >= 0.8:
        level = "ë†’ìŒ"
    elif final_score >= 0.6:
        level = "ì¤‘ê°„"
    else:
        level = "ë‚®ìŒ"
    
    return {
        "score": round(final_score, 2),
        "level": level,
        "issues_found": len(issues),
        "industry": industry,
        "high_confidence_count": high_confidence_issues,
        "category_diversity": unique_categories,
        "analysis_details": {
            "base_confidence": round(avg_confidence, 2),
            "industry_bonus": industry_bonus,
            "diversity_bonus": round(diversity_bonus, 2),
            "quality_bonus": round(quality_bonus, 2)
        }
    }

# ==============================================================================
# ğŸ”„ í•˜ìœ„ í˜¸í™˜ì„± í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ì½”ë“œì™€ì˜ í˜¸í™˜ì„± ìœ ì§€)
# ==============================================================================

def extract_materiality_issues(elements: List[Any]) -> List[Dict[str, Any]]:
    """
    ê¸°ì¡´ í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼ í•¨ìˆ˜.
    ìƒˆë¡œìš´ enhanced ë²„ì „ì„ í˜¸ì¶œí•˜ë˜ ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    enhanced_result = extract_materiality_issues_enhanced(elements)
    
    # ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    issues = enhanced_result["issues"]
    for i, issue in enumerate(issues):
        issue["issue_id"] = i + 1
    
    return issues

def calculate_issue_confidence(text: str, issue_name: str) -> float:
    """ê¸°ì¡´ í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„± ìœ ì§€"""
    # ê¸°ë³¸ í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°
    keywords = ISSUE_KEYWORDS.get(issue_name, [])
    if not keywords:
        return 0.0
    
    confidence = 0.0
    
    # ì •í™•í•œ ì´ìŠˆëª… ë§¤ì¹­
    if issue_name in text:
        confidence += 0.8
    
    # í‚¤ì›Œë“œ ë§¤ì¹­
    matched_keywords = sum(1 for keyword in keywords if keyword in text)
    confidence += (matched_keywords / len(keywords)) * 0.5
    
    # ì¤‘ëŒ€ì„± ì»¨í…ìŠ¤íŠ¸
    if any(word in text for word in ["ì¤‘ëŒ€ì„±", "materiality", "í•µì‹¬ì´ìŠˆ"]):
        confidence += 0.3
        
    # í‘œ/ë§¤íŠ¸ë¦­ìŠ¤ ì»¨í…ìŠ¤íŠ¸
    if any(indicator in text for indicator in ["ë†’ìŒ", "ë³´í†µ", "ë‚®ìŒ", "â”‚", "â”€"]):
        confidence += 0.2
        
    return min(confidence, 1.0)

def calculate_overall_confidence(issues: List[Dict], structure: Dict) -> Dict[str, Any]:
    """ê¸°ì¡´ í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„± ìœ ì§€"""
    if not issues:
        return {"score": 0.0, "level": "ë‚®ìŒ", "reason": "ì´ìŠˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ"}
    
    avg_confidence = sum(issue["confidence"] for issue in issues) / len(issues)
    
    # ë¬¸ì„œ êµ¬ì¡°ì— í…Œì´ë¸”ì´ í¬í•¨ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€
    has_tables = bool(structure.get("tables"))
    if has_tables:
        avg_confidence = min(1.0, avg_confidence + 0.2)
    
    score = round(avg_confidence, 2)
    
    if score >= 0.8:
        level = "ë†’ìŒ"
    elif score >= 0.5:
        level = "ì¤‘ê°„"
    else:
        level = "ë‚®ìŒ"
    
    return {
        "score": score,
        "level": level,
        "issues_found": len(issues),
        "has_tables": has_tables
    } 